{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8y/4mq6cs_x20j1gp06wytwhlwm0000gn/T/ipykernel_3952/2998634654.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Testing with a random input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0minput_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0moutput_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0madjoint_output_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmatvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/speckle38/lib/python3.8/site-packages/scipy/sparse/linalg/_interface.py\u001b[0m in \u001b[0;36mmatvec\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: dimension mismatch"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "\n",
    "class DiscreteGradientOperator(LinearOperator):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__(shape=(2 * shape[0] * shape[1], shape[0] * shape[1]), dtype=np.float64)\n",
    "        self.shape = shape\n",
    "\n",
    "    def _matvec(self, x):\n",
    "        x = x.reshape(self.shape)\n",
    "        gradient_x = np.zeros(self.shape)\n",
    "        gradient_x[:, :-1] = np.diff(x, axis=1)\n",
    "        gradient_y = np.zeros(self.shape)\n",
    "        gradient_y[:-1, :] = np.diff(x, axis=0)\n",
    "        return np.vstack((gradient_x, gradient_y)).ravel()\n",
    "\n",
    "    def _rmatvec(self, x):\n",
    "        x = x.reshape((2, self.shape[0], self.shape[1]))\n",
    "        adjoint_x = np.zeros(self.shape)\n",
    "        adjoint_x[:, :-1] = -np.diff(x[0], axis=1)\n",
    "        adjoint_y = np.zeros(self.shape)\n",
    "        adjoint_y[:-1, :] = -np.diff(x[1], axis=0)\n",
    "        return (adjoint_x + adjoint_y).ravel()\n",
    "\n",
    "# Example usage:\n",
    "M, N = 3, 3\n",
    "operator = DiscreteGradientOperator((M, N))\n",
    "\n",
    "# Testing with a random input\n",
    "input_vector = np.random.rand(M, N)\n",
    "output_vector = operator.matvec(input_vector.ravel())\n",
    "adjoint_output_vector = operator.rmatvec(output_vector)\n",
    "\n",
    "# Reshape results for visualization\n",
    "output_matrix = output_vector.reshape((2, M, N))\n",
    "adjoint_output_matrix = adjoint_output_vector.reshape((M, N))\n",
    "\n",
    "print(\"Input matrix:\")\n",
    "print(input_vector)\n",
    "\n",
    "print(\"\\nOutput matrix (Gradient):\")\n",
    "print(output_matrix)\n",
    "\n",
    "print(\"\\nAdjoint Output matrix:\")\n",
    "print(adjoint_output_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vector.ravel().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input matrix:\n",
      "[0.24268599 0.69366231 0.50293159 0.37640175 0.0072602  0.0696412\n",
      " 0.76010158 0.78677962 0.72341919]\n",
      "\n",
      "Output matrix (Gradient):\n",
      "[[[ 0.45097631 -0.19073072  0.        ]\n",
      "  [-0.36914155  0.06238101  0.        ]\n",
      "  [ 0.02667803 -0.06336043  0.        ]]\n",
      "\n",
      " [[ 0.13371576 -0.68640211 -0.43329038]\n",
      "  [ 0.38369984  0.77951942  0.65377799]\n",
      "  [ 0.          0.          0.        ]]]\n",
      "\n",
      "Adjoint Output matrix:\n",
      "[[ 0.39172296 -1.65665225 -1.08706837]\n",
      " [-0.04782272  0.84190043  0.65377799]\n",
      " [ 0.09003846 -0.06336043  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "\n",
    "class DiscreteGradientOperator(LinearOperator):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__(shape=(2 * shape[0] * shape[1], shape[0] * shape[1]), dtype=np.float64)\n",
    "        # self.shape = shape\n",
    "        self._shape = shape\n",
    "\n",
    "    def _matvec(self, x):\n",
    "        x = x.reshape(self._shape)\n",
    "        gradient_x = np.zeros(self._shape)\n",
    "        gradient_x[:, :-1] = np.diff(x, axis=1)\n",
    "        gradient_y = np.zeros(self._shape)\n",
    "        gradient_y[:-1, :] = np.diff(x, axis=0)\n",
    "        return np.vstack((gradient_x, gradient_y)).ravel()\n",
    "\n",
    "    def _rmatvec(self, x):\n",
    "        x = x.reshape((2, self._shape[0], self._shape[1]))\n",
    "        adjoint_x = np.zeros(self._shape)\n",
    "        adjoint_x[:, :-1] = -np.diff(x[0], axis=1)\n",
    "        adjoint_y = np.zeros(self._shape)\n",
    "        adjoint_y[:-1, :] = -np.diff(x[1], axis=0)\n",
    "        return (adjoint_x + adjoint_y).ravel()\n",
    "\n",
    "# Example usage:\n",
    "M, N = 3, 3\n",
    "operator = DiscreteGradientOperator((M, N))\n",
    "\n",
    "# Testing with a random input\n",
    "input_vector = np.random.rand( M * N)\n",
    "output_vector = operator.matvec(input_vector)\n",
    "adjoint_output_vector = operator.rmatvec(output_vector)\n",
    "\n",
    "# Reshape results for visualization\n",
    "output_matrix = output_vector.reshape((2, M, N))\n",
    "adjoint_output_matrix = adjoint_output_vector.reshape((M, N))\n",
    "\n",
    "print(\"Input matrix:\")\n",
    "print(input_vector)\n",
    "\n",
    "print(\"\\nOutput matrix (Gradient):\")\n",
    "print(output_matrix)\n",
    "\n",
    "print(\"\\nAdjoint Output matrix:\")\n",
    "print(adjoint_output_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjoint test failed.\n",
      "<Ax, y> = -0.09034321750935831, <x, A^*y> = -0.8466242826500311\n",
      "\n",
      "Input matrix:\n",
      "[0.24268599 0.69366231 0.50293159 0.37640175 0.0072602  0.0696412\n",
      " 0.76010158 0.78677962 0.72341919]\n",
      "\n",
      "Output matrix (Gradient):\n",
      "[[[ 0.45097631 -0.19073072  0.        ]\n",
      "  [-0.36914155  0.06238101  0.        ]\n",
      "  [ 0.02667803 -0.06336043  0.        ]]\n",
      "\n",
      " [[ 0.13371576 -0.68640211 -0.43329038]\n",
      "  [ 0.38369984  0.77951942  0.65377799]\n",
      "  [ 0.          0.          0.        ]]]\n",
      "\n",
      "Adjoint Output matrix:\n",
      "[[ 0.39172296 -1.65665225 -1.08706837]\n",
      " [-0.04782272  0.84190043  0.65377799]\n",
      " [ 0.09003846 -0.06336043  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "operator = DiscreteGradientOperator((M, N))\n",
    "\n",
    "# Validation using random vectors\n",
    "x = np.random.rand(M * N)\n",
    "y = np.random.rand(2 * M * N)\n",
    "\n",
    "# Calculate <Ax, y>\n",
    "Ax_y = np.inner(operator.matvec(x), y)\n",
    "\n",
    "# Calculate <x, A^*y>\n",
    "x_Aty = np.inner(x, operator.rmatvec(y))\n",
    "\n",
    "# Check if the two inner products are approximately equal\n",
    "tolerance = 1e-10\n",
    "if np.abs(Ax_y - x_Aty) < tolerance:\n",
    "    print(\"Adjoint test passed!\")\n",
    "else:\n",
    "    print(\"Adjoint test failed.\")\n",
    "    print(f\"<Ax, y> = {Ax_y}, <x, A^*y> = {x_Aty}\")\n",
    "\n",
    "print(\"\\nInput matrix:\")\n",
    "print(input_vector)\n",
    "\n",
    "print(\"\\nOutput matrix (Gradient):\")\n",
    "print(output_matrix)\n",
    "\n",
    "print(\"\\nAdjoint Output matrix:\")\n",
    "print(adjoint_output_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjoint test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot1 = 4.198691211077149\n",
      "dot2 = -5.4347773802340145\n",
      "\n",
      "dot1 = -0.29210075312691375\n",
      "dot2 = 3.7159732466348467\n",
      "\n",
      "dot1 = -6.054453569215181\n",
      "dot2 = 13.11307263217163\n",
      "\n",
      "dot1 = -0.6963332292809347\n",
      "dot2 = 0.041842216145886124\n",
      "\n",
      "dot1 = -3.0442870286015884\n",
      "dot2 = -0.28854972899138565\n",
      "\n",
      "dot1 = -2.2796566826809235\n",
      "dot2 = -2.93777954659334\n",
      "\n",
      "dot1 = 2.134062879232609\n",
      "dot2 = -1.460348447066913\n",
      "\n",
      "dot1 = -0.20834094584167206\n",
      "dot2 = 0.274262440507433\n",
      "\n",
      "dot1 = -9.4686826892827\n",
      "dot2 = 3.176296683808627\n",
      "\n",
      "dot1 = 3.102252710154131\n",
      "dot2 = 3.4899976361411085\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    x = np.random.normal(size=(M,N)).flatten()\n",
    "    y = np.random.normal(size=(2,M,N)).flatten()\n",
    "    Rx = operator.matvec(x)\n",
    "    Rty = operator.rmatvec(y)\n",
    "    dot1 = (Rx*y).sum()\n",
    "    dot2 = (x*Rty).sum()\n",
    "    print(f\"dot1 = {dot1}\")\n",
    "    print(f\"dot2 = {dot2}\")\n",
    "    print(f\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Neumann?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjoint test passed!\n",
      "<Ax, y> = -0.2523205463114665, <x, A^*y> = -0.2523205463114666\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "\n",
    "class DiscreteGradientOperatorNeumann(LinearOperator):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__(shape=(2 * shape[0] * shape[1], shape[0] * shape[1]), dtype=np.float64)\n",
    "        self._shape = shape\n",
    "\n",
    "    def _matvec(self, x):\n",
    "        x = x.reshape(self._shape)\n",
    "        gradient_x = np.zeros(self._shape)\n",
    "        gradient_x[:, :-1] = np.diff(x, axis=1)\n",
    "        gradient_x[:, -1] = x[:, 0] - x[:, -1] # Neumann boundary condition in x\n",
    "        gradient_y = np.zeros(self._shape)\n",
    "        gradient_y[:-1, :] = np.diff(x, axis=0)\n",
    "        gradient_y[-1, :] = x[0, :] - x[-1, :] # Neumann boundary condition in y\n",
    "        return np.vstack((gradient_x, gradient_y)).ravel()\n",
    "\n",
    "    def _rmatvec(self, x):\n",
    "        x = x.reshape((2, self._shape[0], self._shape[1]))\n",
    "        adjoint_x = np.zeros(self._shape)\n",
    "        adjoint_x[:, 0] = x[0, :, -1] - x[0, :, 0] # Neumann boundary condition in x\n",
    "        adjoint_x[:, 1:] = -np.diff(x[0], axis=1)\n",
    "        adjoint_y = np.zeros(self._shape)\n",
    "        adjoint_y[0, :] = x[1, -1, :] - x[1, 0, :] # Neumann boundary condition in y\n",
    "        adjoint_y[1:, :] = -np.diff(x[1], axis=0)\n",
    "        return (adjoint_x + adjoint_y).ravel()\n",
    "\n",
    "# Example usage:\n",
    "M, N = 3, 3\n",
    "operator = DiscreteGradientOperatorNeumann((M, N))\n",
    "\n",
    "# Validation using random vectors\n",
    "x = np.random.rand(M * N)\n",
    "y = np.random.rand(2 * M * N)\n",
    "\n",
    "# Calculate <Ax, y>\n",
    "Ax_y = np.inner(operator.matvec(x), y)\n",
    "\n",
    "# Calculate <x, A^*y>\n",
    "x_Aty = np.inner(x, operator.rmatvec(y))\n",
    "\n",
    "# Check if the two inner products are approximately equal\n",
    "tolerance = 1e-10\n",
    "if np.abs(Ax_y - x_Aty) < tolerance:\n",
    "    print(\"Adjoint test passed!\")\n",
    "    print(f\"<Ax, y> = {Ax_y}, <x, A^*y> = {x_Aty}\")\n",
    "else:\n",
    "    print(\"Adjoint test failed.\")\n",
    "    print(f\"<Ax, y> = {Ax_y}, <x, A^*y> = {x_Aty}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operator.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 9 into shape (18,9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8y/4mq6cs_x20j1gp06wytwhlwm0000gn/T/ipykernel_3952/2280791836.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/speckle38/lib/python3.8/site-packages/scipy/sparse/linalg/_interface.py\u001b[0m in \u001b[0;36mmatvec\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/8y/4mq6cs_x20j1gp06wytwhlwm0000gn/T/ipykernel_3952/1559550233.py\u001b[0m in \u001b[0;36m_matvec\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_matvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mgradient_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mgradient_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 9 into shape (18,9)"
     ]
    }
   ],
   "source": [
    "operator.matvec(input_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirichlet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjoint test failed.\n",
      "<Ax, y> = 0.08396794531985324, <x, A^*y> = -1.8475726079954633\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "\n",
    "class DiscreteGradientOperatorDirichlet(LinearOperator):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__(shape=(2 * shape[0] * shape[1], shape[0] * shape[1]), dtype=np.float64)\n",
    "        self._shape = shape\n",
    "\n",
    "    def _matvec(self, x):\n",
    "        x = x.reshape(self._shape)\n",
    "        gradient_x = np.zeros(self._shape)\n",
    "        gradient_x[:, :-1] = np.diff(x, axis=1)\n",
    "        gradient_y = np.zeros(self._shape)\n",
    "        gradient_y[:-1, :] = np.diff(x, axis=0)\n",
    "        return np.vstack((gradient_x, gradient_y)).ravel()\n",
    "\n",
    "    def _rmatvec(self, x):\n",
    "        x = x.reshape((2, self._shape[0], self._shape[1]))\n",
    "        adjoint_x = np.zeros(self._shape)\n",
    "        adjoint_x[:, 1:] = -np.diff(x[0], axis=1)\n",
    "        adjoint_y = np.zeros(self._shape)\n",
    "        adjoint_y[1:, :] = -np.diff(x[1], axis=0)\n",
    "        return (adjoint_x + adjoint_y).ravel()\n",
    "\n",
    "# Example usage:\n",
    "M, N = 3, 3\n",
    "operator = DiscreteGradientOperatorDirichlet((M, N))\n",
    "\n",
    "# Validation using random vectors\n",
    "x = np.random.rand(M * N)\n",
    "y = np.random.rand(2 * M * N)\n",
    "\n",
    "# Calculate <Ax, y>\n",
    "Ax_y = np.inner(operator.matvec(x), y)\n",
    "\n",
    "# Calculate <x, A^*y>\n",
    "x_Aty = np.inner(x, operator.rmatvec(y))\n",
    "\n",
    "# Check if the two inner products are approximately equal\n",
    "tolerance = 1e-10\n",
    "if np.abs(Ax_y - x_Aty) < tolerance:\n",
    "    print(\"Adjoint test passed!\")\n",
    "else:\n",
    "    print(\"Adjoint test failed.\")\n",
    "    print(f\"<Ax, y> = {Ax_y}, <x, A^*y> = {x_Aty}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjoint test failed.\n",
      "<Ax, y> = -0.34561712332317446, <x, A^*y> = -1.2217100556005915\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "\n",
    "class DiscreteGradientOperatorDirichlet(LinearOperator):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__(shape=(2 * shape[0] * shape[1], shape[0] * shape[1]), dtype=np.float64)\n",
    "        self._shape = shape\n",
    "\n",
    "    def _matvec(self, x):\n",
    "        x = x.reshape(self._shape)\n",
    "        gradient_x = np.diff(x, axis=1)\n",
    "        gradient_y = np.diff(x, axis=0)\n",
    "        \n",
    "        # Apply Dirichlet zero boundary condition\n",
    "        gradient_x = np.hstack((gradient_x, np.zeros((self._shape[0], 1))))\n",
    "        gradient_y = np.vstack((gradient_y, np.zeros((1, self._shape[1]))))\n",
    "        \n",
    "        return np.vstack((gradient_x, gradient_y)).ravel()\n",
    "\n",
    "    def _rmatvec(self, x):\n",
    "        x = x.reshape((2, self._shape[0], self._shape[1]))\n",
    "        adjoint_x = -np.diff(x[0], axis=1)\n",
    "        adjoint_y = -np.diff(x[1], axis=0)\n",
    "        \n",
    "        # Remove last column and last row to account for Dirichlet zero boundary condition\n",
    "        adjoint_x = adjoint_x[:, :-1]\n",
    "        adjoint_y = adjoint_y[:-1, :]\n",
    "        \n",
    "        return (adjoint_x + adjoint_y).ravel()\n",
    "\n",
    "# Example usage:\n",
    "M, N = 3, 3\n",
    "operator = DiscreteGradientOperatorDirichlet((M, N))\n",
    "\n",
    "# Validation using random vectors\n",
    "x = np.random.rand(M * N)\n",
    "y = np.random.rand(2 * M * N)\n",
    "\n",
    "# Calculate <Ax, y>\n",
    "Ax_y = np.inner(operator.matvec(x), y)\n",
    "\n",
    "# Calculate <x, A^*y>\n",
    "x_Aty = np.inner(x, operator.rmatvec(y))\n",
    "\n",
    "# Check if the two inner products are approximately equal\n",
    "tolerance = 1e-10\n",
    "if np.abs(Ax_y - x_Aty) < tolerance:\n",
    "    print(\"Adjoint test passed!\")\n",
    "else:\n",
    "    print(\"Adjoint test failed.\")\n",
    "    print(f\"<Ax, y> = {Ax_y}, <x, A^*y> = {x_Aty}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (0,3) into shape (2,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8y/4mq6cs_x20j1gp06wytwhlwm0000gn/T/ipykernel_3952/3335365465.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Calculate <Ax, y>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mAx_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Calculate <x, A^*y>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/speckle38/lib/python3.8/site-packages/scipy/sparse/linalg/_interface.py\u001b[0m in \u001b[0;36mmatvec\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/8y/4mq6cs_x20j1gp06wytwhlwm0000gn/T/ipykernel_3952/3335365465.py\u001b[0m in \u001b[0;36m_matvec\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mgradient_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mgradient_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (0,3) into shape (2,3)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "\n",
    "class DiscreteGradientOperatorDirichlet(LinearOperator):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__(shape=(2 * shape[0] * shape[1], shape[0] * shape[1]), dtype=np.float64)\n",
    "        self._shape = shape\n",
    "        self.M, self.N = shape\n",
    "\n",
    "    def _matvec(self, x):\n",
    "        x = x.reshape(self._shape)\n",
    "        gradient_x = np.zeros((self.M, self.N))\n",
    "        gradient_y = np.zeros((self.M, self.N))\n",
    "\n",
    "        gradient_x[:, :-1] = np.diff(x[:self.M,:], axis=1)\n",
    "        gradient_y[:-1, :] = np.diff(x[self.M:,:], axis=0)\n",
    "\n",
    "        return np.vstack((gradient_x.ravel(), gradient_y.ravel()))\n",
    "\n",
    "    def _rmatvec(self, x):\n",
    "        x = x.reshape((2, self.M, self.N))\n",
    "\n",
    "        adjoint_x = np.zeros((self.M, self.N))\n",
    "        adjoint_y = np.zeros((self.M, self.N))\n",
    "\n",
    "        adjoint_x[:, 0] = -x[0, :, 0]\n",
    "        adjoint_x[:, -1] = x[0, :, -1]\n",
    "        adjoint_x[:, 1:-1] = -np.diff(x[0], axis=1)\n",
    "\n",
    "        adjoint_y[0, :] = -x[1, 0, :]\n",
    "        adjoint_y[-1, :] = x[1, -1, :]\n",
    "        adjoint_y[1:-1, :] = -np.diff(x[1], axis=0)\n",
    "\n",
    "        return (adjoint_x + adjoint_y).ravel()\n",
    "\n",
    "# Example usage:\n",
    "M, N = 3, 3\n",
    "operator = DiscreteGradientOperatorDirichlet((M, N))\n",
    "\n",
    "# Validation using random vectors\n",
    "x = np.random.rand(M * N)\n",
    "y = np.random.rand(2* M * N)\n",
    "\n",
    "# Calculate <Ax, y>\n",
    "Ax_y = np.inner(operator.matvec(x), y)\n",
    "\n",
    "# Calculate <x, A^*y>\n",
    "x_Aty = np.inner(x, operator.rmatvec(y))\n",
    "\n",
    "# Check if the two inner products are approximately equal\n",
    "tolerance = 1e-10\n",
    "if np.abs(Ax_y - x_Aty) < tolerance:\n",
    "    print(\"Adjoint test passed!\")\n",
    "else:\n",
    "    print(\"Adjoint test failed.\")\n",
    "    print(f\"<Ax, y> = {Ax_y}, <x, A^*y> = {x_Aty}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speckle38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
